<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>MPI_Op_create(MPI_User_function *function, 
  int commute, 
  MPI_Op *op) function</title>
<link rel="stylesheet" href="../style.css" type="text/css" charset="utf-8">

</head>

<body>
	<div class="background">
    	<div class="tab_box">
 
            <div class="tab_box_middle">
            	<div class="main_box">
                	<div class="text_box">
                    	<div class="text_box_top">
                        </div>
                        <div class="text_box_middle">
                        	<div class="text_box_middle_text">
 
<a name="MPI_Op_create"><h1><font size="5">MPI_Op_create</font></h1></a>
Creates a user-defined combination function handle 
<font size="3">
<pre class="syntax" xml:space="preserve" style="background-color: #DDDDDD"><b>int MPI_Op_create(</b>
  <b>MPI_User_function</b> *<i>function</i><b>,</b>
  <b>int</b> <i>commute</i><b>,</b>
  <b>MPI_Op</b> *<i>op</i>
<b>);</b>
</pre></font>
<h4>Parameters</h4>
<dl>
<dt><i>function </i></dt><dd>[in] user defined function (function) 

</dd><dt><i>commute </i></dt><dd>[in] true if commutative;  false otherwise. (logical)
</dd><dt><i>op </i></dt>
<dd>[out] operation (handle) 
</dd></dl>
<p>
</p><h4>Remarks</h4>
		<p>MPI_OP_CREATE binds a user-defined global operation to an op handle 
		that can subsequently be used in MPI_REDUCE, MPI_ALLREDUCE, 
		MPI_REDUCE_SCATTER, and MPI_SCAN. The user-defined operation is assumed 
		to be associative. If commute <i>=</i> <tt>true</tt>, then the operation 
		should be both commutative and associative. If commute <i>=</i> <tt>
		false</tt>, then the order of operands is fixed and is defined to be in 
		ascending, process rank order, beginning with process zero. The order of 
		evaluation can be changed, talking advantage of the associativity of the 
		operation. If commute <i>=</i> <tt>true</tt> then the order of 
		evaluation can be changed, taking advantage of commutativity and 
		associativity. </p>
		<p>function is the user-defined function, which must have the following 
		four arguments: invec, inoutvec, len and datatype. </p>
		<p>The ANSI-C prototype for the function is the following. <br>
&nbsp;</p>
		<pre><tt>typedef void MPI_User_function( void *invec, void *inoutvec, int *len, 
                                                MPI_Datatype *datatype); 
</tt></pre>
		The Fortran declaration of the user-defined function appears below. <br>
&nbsp;<pre><tt>FUNCTION USER_FUNCTION( INVEC(*), INOUTVEC(*), LEN, TYPE) 
&lt;type&gt; INVEC(LEN), INOUTVEC(LEN) 
 INTEGER LEN, TYPE 
</tt></pre>
		The datatype argument is a handle to the data type that was passed into 
		the call to MPI_REDUCE. The user reduce function should be written such 
		that the following holds: Let u[0], ... , u[len-1] be the len elements 
		in the communication buffer described by the arguments invec, len and 
		datatype when the function is invoked; let v[0], ... , v[len-1] be len 
		elements in the communication buffer described by the arguments inoutvec, 
		len and datatype when the function is invoked; let w[0], ... , w[len-1] 
		be len elements in the communication buffer described by the arguments 
		inoutvec, len and datatype when the function returns; then w[i] = u[i]<img src="img133.gif"> 
		v[i], for i=0 , ... , len-1, where <img src="img134.gif"> is the reduce 
		operation that the function computes. 
		<p>Informally, we can think of invec and inoutvec as arrays of len 
		elements that function is combining. The result of the reduction 
		over-writes values in inoutvec, hence the name. Each invocation of the 
		function results in the pointwise evaluation of the reduce operator on 
		len elements: I.e, the function returns in inoutvec[i] the value
		<img src="img135.gif"> , for <img src="img136.gif"> , where
		<img src="img137.gif"> is the combining operation computed by the 
		function. </p>
		<p><br>
		[]<em> Rationale.</em> </p>
		<p>The len argument allows MPI_REDUCE to avoid calling the function for 
		each element in the input buffer. Rather, the system can choose to apply 
		the function to chunks of input. In C, it is passed in as a reference 
		for reasons of compatibility with Fortran. </p>
		<p>By internally comparing the value of the datatype argument to known, 
		global handles, it is possible to overload the use of a single 
		user-defined function for several, different data types. (<em> End of 
		rationale.</em>) <br>
		General datatypes may be passed to the user function. However, use of 
		datatypes that are not contiguous is likely to lead to inefficiencies.
		</p>
		<p>No MPI communication function may be called inside the user function. 
		MPI_ABORT may be called inside the function in case of an error. </p>
		<p><br>
		<em>Advice to users.</em></p>
		<p>Suppose one defines a library of user-defined reduce functions that 
		are overloaded: the datatype argument is used to select the right 
		execution path at each invocation, according to the types of the 
		operands. The user-defined reduce function cannot "decode" the 
		datatype argument that it is passed, and cannot identify, by itself, the 
		correspondence between the datatype handles and the datatype they 
		represent. This correspondence was established when the datatypes were 
		created. Before the library is used, a library initialization preamble 
		must be executed. This preamble code will define the datatypes that are 
		used by the library, and store handles to these datatypes in global, 
		static variables that are shared by the user code and the library code.
		</p>
		<p>The Fortran version of MPI_REDUCE will invoke a user-defined reduce 
		function using the Fortran calling conventions and will pass a 
		Fortran-type datatype argument; the C version will use C calling 
		convention and the C representation of a datatype handle. Users who plan 
		to mix languages should define their reduction functions accordingly.</p>
		<h4>Notes on the user function</h4>
The calling list for the user function type is
<font size="3">
<pre class="syntax" xml:space="preserve"> typedef void (MPI_User_function) ( void * a, void * b, int * len, MPI_Datatype * ); 
</pre></font>

where the operation is <tt><font size="2">b[i] = a[i] op b[i]</font></tt>, for <tt><font size="2">i=0,...,len-1</font></tt>.  A pointer
to the datatype given to the MPI collective computation routine (i.e.,
<tt><font size="2"><a href="MPI_Reduce.html">MPI_Reduce</a></font></tt>, <tt><font size="2"><a href="MPI_Allreduce.html">MPI_Allreduce</a></font></tt>, <tt><font size="2"><a href="MPI_Scan.html">MPI_Scan</a></font></tt>, or <tt><font size="2"><a href="MPI_Reduce_scatter.html">MPI_Reduce_scatter</a></font></tt>) is also
passed to the user-specified routine.
<p>
</p><h4>Thread and Interrupt Safety</h4>
<p>
This routine is thread-safe.  This means that this routine may be
safely used by multiple threads without the need for any user-provided
thread locks.  However, the routine is not interrupt safe.  Typically,
this is due to the use of memory allocation routines such as <tt><font size="2">malloc
</font></tt>or other non-MPICH runtime routines that are themselves not interrupt-safe.
</p><p>
</p><h4>Notes for Fortran</h4>
All MPI routines in Fortran (except for <tt><font size="2">MPI_WTIME</font></tt> and <tt><font size="2">MPI_WTICK</font></tt>) have
an additional argument <tt><font size="2">ierr</font></tt> at the end of the argument list.  <tt><font size="2">ierr
</font></tt>is an integer and has the same meaning as the return value of the routine
in C.  In Fortran, MPI routines are subroutines, and are invoked with the
<tt><font size="2">call</font></tt> statement.
<p>
All MPI objects (e.g., <tt><font size="2">MPI_Datatype</font></tt>, <tt><font size="2">MPI_Comm</font></tt>) are of type <tt><font size="2">INTEGER
</font></tt>in Fortran.
</p><p>
</p><h4>Notes on collective operations</h4>
<p>
The reduction functions (<tt><font size="2">MPI_Op</font></tt>) do not return an error value.  As a result,
if the functions detect an error, all they can do is either call <tt><font size="2">MPI_Abort
</font></tt>or silently skip the problem.  Thus, if you change the error handler from
<tt><font size="2">MPI_ERRORS_ARE_FATAL</font></tt> to something else, for example, <tt><font size="2">MPI_ERRORS_RETURN</font></tt>,
then no error may be indicated.
</p><p>
The reason for this is the performance problems in ensuring that
all collective routines return the same error value.
</p><p>
</p><h4>Errors</h4>
<p>
All MPI routines (except <tt><font size="2"><a href="MPI_Wtime.html">MPI_Wtime</a></font></tt> and <tt><font size="2"><a href="MPI_Wtick.html">MPI_Wtick</a></font></tt>) return an error value;
C routines as the value of the function and Fortran routines in the last
argument.  Before the value is returned, the current MPI error handler is
called.  By default, this error handler aborts the MPI job.  The error handler
may be changed with <tt><font size="2"><a href="MPI_Comm_set_errhandler.html">MPI_Comm_set_errhandler</a></font></tt> (for communicators),
<tt><font size="2"><a href="MPI_File_set_errhandler.html">MPI_File_set_errhandler</a></font></tt> (for files), and <tt><font size="2"><a href="MPI_Win_set_errhandler.html">MPI_Win_set_errhandler</a></font></tt> (for
RMA windows).  The MPI-1 routine <tt><font size="2"><a href="MPI_Errhandler_set.html">MPI_Errhandler_set</a></font></tt> may be used but
its use is deprecated.  The predefined error handler
<tt><font size="2">MPI_ERRORS_RETURN</font></tt> may be used to cause error values to be returned.
Note that MPI does <em>not</em> guarentee that an MPI program can continue past
an error; however, MPI implementations will attempt to continue whenever
possible.
</p><p>
</p><dl><dt><i>MPI_SUCCESS </i></dt> <dd> No error; MPI routine completed successfully.
</dd></dl>
<p>
</p><h4>See Also</h4>
 <a href="MPI_Op_free.html">MPI_Op_free</a>
<br>
<h4>Example Code</h4>
<p>The following sample code illustrates <a href="MPI_Op_create.html">MPI_Op_create</a>.
</p>
<font size="2" color="#0000ff">
#include</font><font size="2"> "mpi.h"<br>
</font><font size="2" color="#0000ff">
#include</font><font size="2"> &lt;stdio.h&gt;<br>
&nbsp;<br>
</font><font size="2" color="#0000ff">
void</font><font size="2"> addem ( </font><font size="2" color="#0000ff">int</font><font size="2"> 
*, </font><font size="2" color="#0000ff">int</font><font size="2"> *, </font>
<font size="2" color="#0000ff">int</font><font size="2"> *, MPI_Datatype * );<br>
&nbsp;<br>
</font><font size="2" color="#0000ff">
void</font><font size="2"> addem(</font><font size="2" color="#0000ff">int</font><font size="2"> 
*invec, </font><font size="2" color="#0000ff">int</font><font size="2"> *inoutvec,
</font><font size="2" color="#0000ff">int</font><font size="2"> *len, 
MPI_Datatype *dtype)<br>
{<br>
&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#0000ff">int</font><font size="2"> i;<br>
</font><font size="2" color="#0000ff">&nbsp;&nbsp;&nbsp; for</font><font size="2"> ( i=0; 
i&lt;*len; i++ ) <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
inoutvec[i] += invec[i];<br>
}<br>
&nbsp;<br>
</font><font size="2" color="#0000ff">
int</font><font size="2"> main( </font><font size="2" color="#0000ff">int</font><font size="2"> 
argc, </font><font size="2" color="#0000ff">char</font><font size="2"> **argv )<br>
{<br>
</font><font size="2" color="#0000ff">&nbsp;&nbsp;&nbsp; int</font><font size="2"> rank, size, 
i;<br>
</font><font size="2" color="#0000ff">&nbsp;&nbsp;&nbsp; int</font><font size="2"> data;<br>
&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#0000ff">int</font><font size="2"> errors=0;<br>
</font><font size="2" color="#0000ff">&nbsp;&nbsp;&nbsp; int</font><font size="2"> result = 
-100;<br>
&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#0000ff">int</font><font size="2"> 
correct_result;<br>
&nbsp;&nbsp;&nbsp;
MPI_Op op;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;
<a href="MPI_Init.html">MPI_Init</a>( &amp;argc, &amp;argv );<br>
&nbsp;&nbsp;&nbsp;
<a href="MPI_Comm_rank.html">MPI_Comm_rank</a>( MPI_COMM_WORLD, &amp;rank );<br>
&nbsp;&nbsp;&nbsp;
<a href="MPI_Comm_size.html">MPI_Comm_size</a>( MPI_COMM_WORLD, &amp;size );<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;
data = rank;<br>
&nbsp;&nbsp;&nbsp;
<a href="MPI_Op_create.html">MPI_Op_create</a>( (MPI_User_function *)addem, 1, &amp;op );<br>
&nbsp;&nbsp;&nbsp;
<a href="MPI_Reduce.html">MPI_Reduce</a> ( &amp;data, &amp;result, 1, MPI_INT, op, 0, MPI_COMM_WORLD );<br>
&nbsp;&nbsp;&nbsp;
<a href="MPI_Bcast.html">MPI_Bcast</a> ( &amp;result, 1, MPI_INT, 0, MPI_COMM_WORLD );<br>
&nbsp;&nbsp;&nbsp;
<a href="MPI_Op_free.html">MPI_Op_free</a>( &amp;op );<br>
&nbsp;&nbsp;&nbsp;
correct_result = 0;<br>
</font><font size="2" color="#0000ff">&nbsp;&nbsp;&nbsp; for</font><font size="2">(i=0;i&lt;size;i++)
<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
correct_result += i;<br>
</font><font size="2" color="#0000ff">&nbsp;&nbsp;&nbsp; if</font><font size="2"> (result != 
correct_result) errors++;<br>
&nbsp;<br>
&nbsp;&nbsp;&nbsp;
<a href="MPI_Finalize.html">MPI_Finalize</a>();<br>
</font><font size="2" color="#0000ff">&nbsp;&nbsp;&nbsp; return</font><font size="2"> errors;<br>
}<br>
</font>
</div>
                        </div>
                        <div class="text_box_bottom">
                        </div>
                    </div>
                    <div class="note_text_box">
                        <div class="note_text_box_top"></div>
                        <div class="note_text_box_middle">
 
                        </div>
                        <div class="note_text_box_bottom"></div>
                    </div>
                    <div class="ad_under_text_box">
                        <div class="ad_under_text_box_top"></div>
                        <div class="ad_under_text_box_middle">
                            <div class="ad_under_text_box_middle_text">
                            <script type="text/javascript"><!--
google_ad_client = "pub-0347391630140593";
/* Right panel wide skyscraper ad */
google_ad_slot = "3437924454";
google_ad_width = 160;
google_ad_height = 600;
//-->
</script>
<script type="text/javascript" src="http://pagead2.googlesyndication.com/pagead/show_ads.js">
</script><ins style="display:inline-table;border:none;height:600px;margin:0;padding:0;position:relative;visibility:visible;width:160px;background-color:transparent"><ins id="aswift_0_anchor" style="display:block;border:none;height:600px;margin:0;padding:0;position:relative;visibility:visible;width:160px;background-color:transparent"><iframe width="160" height="600" frameborder="0" marginwidth="0" marginheight="0" vspace="0" hspace="0" allowtransparency="true" scrolling="no" onload="var i=this.id,s=window.google_iframe_oncopy,H=s&amp;&amp;s.handlers,h=H&amp;&amp;H[i],w=this.contentWindow,d;try{d=w.document}catch(e){}if(h&amp;&amp;d&amp;&amp;(!d.body||!d.body.firstChild)){if(h.call){setTimeout(h,0)}else if(h.match){try{h=s.upd(h,i)}catch(e){}w.location.replace(h)}}" id="aswift_0" name="aswift_0" style="left:0;position:absolute;top:0;"></iframe></ins></ins>
                            </div>
                        </div>
                        <div class="ad_under_text_box_bottom"></div>
                    </div>
                </div>
            </div>
            <div class="tab_box_bottom">
            </div>
        </div>
        <div class="copyright">
 
        </div>
	</div>


</body></html>