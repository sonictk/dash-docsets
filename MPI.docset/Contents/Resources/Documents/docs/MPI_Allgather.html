<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>MPI_Allgather(void *sendbuf, 
  int sendcount, 
  MPI_Datatype sendtype, 
  void *recvbuf, 
  int recvcount, 
  MPI_Datatype recvtype, 
  MPI_Comm comm
) function</title>
<link rel="stylesheet" href="../style.css" type="text/css" charset="utf-8">
</head>

<body>
	<div class="background">
    	<div class="tab_box">

            <div class="tab_box_middle">
            	<div class="main_box">
                	<div class="text_box">
                    	<div class="text_box_top">
                        </div>
                        <div class="text_box_middle">
                        	<div class="text_box_middle_text">

<a name="MPI_Allgather"><h1><font size="5">MPI_Allgather</font></h1></a>
Gathers data from all tasks and distribute the combined data to all tasks 
<font size="3">
<pre class="syntax" xml:space="preserve" style="background-color: #DDDDDD"><b>int MPI_Allgather(</b>
  <b>void</b> *<i>sendbuf</i><b>,</b>
  <b>int</b> <i>sendcount</i><b>,</b>
  <b>MPI_Datatype</b> <i>sendtype</i><b>,</b>
  <b>void</b> *<i>recvbuf</i><b>,</b>
  <b>int</b> <i>recvcount</i><b>,</b>
  <b>MPI_Datatype</b> <i>recvtype</i><b>,</b>
  <b>MPI_Comm</b> <i>comm</i>
<b>);</b>
</pre></font>
<h4>Parameters</h4>
<dl>
<dt><i>sendbuf </i></dt><dd>[in] starting address of send buffer (choice) 

</dd><dt><i>sendcount </i></dt><dd>[in] number of elements in send buffer (integer) 

</dd><dt><i>sendtype </i></dt><dd>[in] data type of send buffer elements (handle) 

<dl>
<dt><i>recvbuf </i></dt>
<dd>[out] address of receive buffer (choice) 
</dd></dl>

</dd><dt><i>recvcount </i></dt><dd>[in] number of elements received from any process (integer) 

</dd><dt><i>recvtype </i></dt><dd>[in] data type of receive buffer elements (handle) 

</dd><dt><i>comm </i></dt><dd>[in] communicator (handle) 
</dd></dl>
<h4>Remarks</h4>
The MPI standard (1.0 and 1.1) says that
<br>
<p>
&nbsp;&nbsp;&nbsp;
The jth block of data sent from  each proess is received by every process
and placed in the jth block of the buffer <tt><font size="2">recvbuf</font></tt>.
<br>
</p><p>
This is misleading; a better description is
<br>
</p><p>
&nbsp;&nbsp;&nbsp;
The block of data sent from the jth process is received by every
process and placed in the jth block of the buffer <tt><font size="2">recvbuf</font></tt>.
<br>
</p><p>
		</p><p>MPI_ALLGATHER can be thought of as MPI_GATHER, but where all 
		processes receive the result, instead of just the root. The <tt>j</tt>th 
		block of data sent from each process is received by every process and 
		placed in the <tt>j</tt>th block of the buffer recvbuf. </p>
		<p>The type signature associated with sendcount, sendtype, at a process 
		must be equal to the type signature associated with recvcount, recvtype 
		at any other process. </p>
		<p>The outcome of a call to MPI_ALLGATHER(...) is as if all processes 
		executed <tt>n</tt> calls to <br>
&nbsp;</p>
		<pre><tt>MPI_GATHER(sendbuf,sendcount,sendtype,recvbuf,recvcount, recvtype,root,comm), 
</tt></pre>
		for <tt>root = 0 , ..., n-1</tt>. The rules for correct usage of 
		MPI_ALLGATHER are easily found from the corresponding rules for 
		MPI_GATHER.<p>The "in place" option for intracommunicators is 
		specified by passing the value MPI_IN_PLACE to the argument sendbuf at 
		all processes. sendcount and sendtype are ignored. Then the input data 
		of each process is assumed to be in the area where that process would 
		receive its own contribution to the receive buffer. Specifically, the 
		outcome of a call to MPI_ALLGATHER in the "in place" case is as if all 
		processes executed <i>n</i> calls to <br>
&nbsp;</p>
		<pre><tt>    MPI_GATHER( MPI_IN_PLACE, 0, MPI_DATATYPE_NULL, recvbuf, recvcount, recvtype, root, comm ) 
</tt></pre>
		for <tt>root = 0, ..., n - 1</tt>. 
		<p>If comm is an intercommunicator, then each process in group A 
		contributes a data item; these items are concatenated and the result is 
		stored at each process in group B. Conversely the concatenation of the 
		contributions of the processes in group B is stored at each process in 
		group A. The send buffer arguments in group A must be consistent with 
		the receive buffer arguments in group B, and vice versa. </p>
		<p>&nbsp;</p>
		<p><br>
		<em>Advice to users.</em> </p>
		<p>The communication pattern of MPI_ALLGATHER executed on an 
		intercommunication domain need not be symmetric. The number of items 
		sent by processes in group A (as specified by the arguments sendcount, 
		sendtype in group A and the arguments recvcount, recvtype in group B), 
		need not equal the number of items sent by processes in group B (as 
		specified by the arguments sendcount, sendtype in group B and the 
		arguments recvcount, recvtype in group A). In particular, one can move 
		data in only one direction by specifying sendcount = 0 for the 
		communication in the reverse direction. </p>
<h4>Thread and Interrupt Safety</h4>
<p>
This routine is thread-safe.  This means that this routine may be
safely used by multiple threads without the need for any user-provided
thread locks.  However, the routine is not interrupt safe.  Typically,
this is due to the use of memory allocation routines such as <tt><font size="2">malloc
</font></tt>or other non-MPICH runtime routines that are themselves not interrupt-safe.
</p><p>
</p><h4>Notes for Fortran</h4>
All MPI routines in Fortran (except for <tt><font size="2">MPI_WTIME</font></tt> and <tt><font size="2">MPI_WTICK</font></tt>) have
an additional argument <tt><font size="2">ierr</font></tt> at the end of the argument list.  <tt><font size="2">ierr
</font></tt>is an integer and has the same meaning as the return value of the routine
in C.  In Fortran, MPI routines are subroutines, and are invoked with the
<tt><font size="2">call</font></tt> statement.
<p>
All MPI objects (e.g., <tt><font size="2">MPI_Datatype</font></tt>, <tt><font size="2">MPI_Comm</font></tt>) are of type <tt><font size="2">INTEGER
</font></tt>in Fortran.
</p><p>
</p><h4>Errors</h4>
<p>
All MPI routines (except <tt><font size="2"><a href="MPI_Wtime.html">MPI_Wtime</a></font></tt> and <tt><font size="2"><a href="MPI_Wtick.html">MPI_Wtick</a></font></tt>) return an error value;
C routines as the value of the function and Fortran routines in the last
argument.  Before the value is returned, the current MPI error handler is
called.  By default, this error handler aborts the MPI job.  The error handler
may be changed with <tt><font size="2"><a href="MPI_Comm_set_errhandler.html">MPI_Comm_set_errhandler</a></font></tt> (for communicators),
<tt><font size="2"><a href="MPI_File_set_errhandler.html">MPI_File_set_errhandler</a></font></tt> (for files), and <tt><font size="2"><a href="MPI_Win_set_errhandler.html">MPI_Win_set_errhandler</a></font></tt> (for
RMA windows).  The MPI-1 routine <tt><font size="2"><a href="MPI_Errhandler_set.html">MPI_Errhandler_set</a></font></tt> may be used but
its use is deprecated.  The predefined error handler
<tt><font size="2">MPI_ERRORS_RETURN</font></tt> may be used to cause error values to be returned.
Note that MPI does <em>not</em> guarentee that an MPI program can continue past
an error; however, MPI implementations will attempt to continue whenever
possible.
</p><p>
</p><dl><dt><i>MPI_ERR_COMM </i></dt> <dd> Invalid communicator.  A common error is to use a null
communicator in a call (not even allowed in <tt><font size="2"><a href="MPI_Comm_rank.html">MPI_Comm_rank</a></font></tt>).
</dd></dl>
<dl><dt><i>MPI_ERR_COUNT </i></dt> <dd> Invalid count argument.  Count arguments must be 
non-negative; a count of zero is often valid.
</dd></dl>
<dl><dt><i>MPI_ERR_TYPE </i></dt> <dd> Invalid datatype argument.  May be an uncommitted 
MPI_Datatype (see <tt><font size="2"><a href="MPI_Type_commit.html">MPI_Type_commit</a></font></tt>).
</dd></dl>
<dl><dt><i>MPI_ERR_BUFFER </i></dt> <dd> Invalid buffer pointer.  Usually a null buffer where
one is not valid.
</dd></dl>

<h4>Example Code</h4>
<p>The following sample code illustrates <a href="MPI_Allgather.html">MPI_Allgather</a>.
<br>
&nbsp;</p><p><font size="2" color="#0000ff">
#include</font><font size="2"> "mpi.h"<br>
</font><font size="2" color="#0000ff">
#include</font><font size="2"> &lt;stdio.h&gt;<br>
<br>
</font><font size="2" color="#0000ff">
#define</font><font size="2"> MAX_PROCESSES 10<br>
<br>
</font><font size="2" color="#0000ff">
int</font><font size="2"> main( </font><font size="2" color="#0000ff">int</font><font size="2"> 
argc, </font><font size="2" color="#0000ff">char</font><font size="2"> **argv )<br>
{<br>
</font><font size="2" color="#0000ff">&nbsp;&nbsp;&nbsp; int</font><font size="2"> rank, size, 
i,j;<br>
&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#0000ff">int</font><font size="2"> 
table[MAX_PROCESSES][MAX_PROCESSES];<br>
&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#0000ff">int</font><font size="2"> errors=0;<br>
&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#0000ff">int</font><font size="2"> participants;<br>
<br>
&nbsp;&nbsp;&nbsp;
<a href="MPI_Init.html">MPI_Init</a>( &amp;argc, &amp;argv );<br>
&nbsp;&nbsp;&nbsp;
<a href="MPI_Comm_rank.html">MPI_Comm_rank</a>( MPI_COMM_WORLD, &amp;rank );<br>
&nbsp;&nbsp;&nbsp;
<a href="MPI_Comm_size.html">MPI_Comm_size</a>( MPI_COMM_WORLD, &amp;size );<br>
&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#008000">/* Exactly MAX_PROCESSES processes can 
participate */<br>
&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#0000ff">if</font><font size="2"> ( size &gt;= 
MAX_PROCESSES ) participants = MAX_PROCESSES;<br>
&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#0000ff">else<br>
&nbsp;&nbsp;&nbsp;
</font><font size="2">
{<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
fprintf( stderr, "Number of processors must be at least %d\n", MAX_PROCESSES 
);fflush(stderr);<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<a href="MPI_Abort.html">MPI_Abort</a>( MPI_COMM_WORLD, 1 );<br>
&nbsp;&nbsp;&nbsp;
}<br>
&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#0000ff">if</font><font size="2"> ( (rank &lt; 
participants) ) {<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#008000">/* Determine what rows are my 
responsibility */<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#0000ff">int</font><font size="2"> block_size = 
MAX_PROCESSES / participants;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#0000ff">int</font><font size="2"> begin_row = 
rank * block_size;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#0000ff">int</font><font size="2"> end_row = 
(rank+1) * block_size;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#0000ff">int</font><font size="2"> send_count = 
block_size * MAX_PROCESSES;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#0000ff">int</font><font size="2"> recv_count = 
send_count;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#008000">/* Paint my rows my color */<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#0000ff">for</font><font size="2"> (i=begin_row; 
i&lt;end_row ;i++)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#0000ff">for</font><font size="2"> (j=0; j&lt;MAX_PROCESSES; 
j++)<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
table[i][j] = rank + 10;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#008000">/* Everybody gets the gathered table */<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</font><font size="2">
<a href="MPI_Allgather.html">MPI_Allgather</a>(&amp;table[begin_row][0], send_count, MPI_INT, <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&amp;table[0][0], recv_count, MPI_INT, MPI_COMM_WORLD);<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#008000">/* Everybody should have the same table 
now, */<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#0000ff">for</font><font size="2"> (i=0; i&lt;MAX_PROCESSES;i++) 
{<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#0000ff">if</font><font size="2"> ( (table[i][0] 
- table[i][MAX_PROCESSES-1] !=0) ) <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
errors++;<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
}<br>
&nbsp;&nbsp;&nbsp;
} <br>
&nbsp;&nbsp;&nbsp;
<a href="MPI_Finalize.html">MPI_Finalize</a>();<br>
&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#0000ff">if</font><font size="2"> (errors)<br>
&nbsp;&nbsp;&nbsp;
{<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
printf( "[%d] done with ERRORS(%d)!\n", rank, errors );fflush(stdout);<br>
&nbsp;&nbsp;&nbsp;
}<br>
&nbsp;&nbsp;&nbsp;
</font><font size="2" color="#0000ff">return</font><font size="2"> errors;<br>
}<br>
</font>

</p></div>


</body></html>